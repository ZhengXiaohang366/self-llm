{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc546b9-52cc-495c-bcb2-915559ba782a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 20:26:21.229 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /root/miniconda3/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de4f32d68c34e3694fe3d04e2bbec54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "/root/miniconda3/lib/python3.10/site-packages/accelerate/utils/modeling.py:1462: UserWarning: Current model requires 469769216 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import streamlit as st\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "# 在侧边栏中创建一个标题和一个链接\n",
    "with st.sidebar:\n",
    "    st.markdown(\"## chat-huan LLM\")\n",
    "    # 创建一个滑块，用于选择最大长度，范围在 0 到 8192 之间，默认值为 512（Qwen2.5 支持 128K 上下文，并能生成最多 8K tokens）\n",
    "    max_length = st.slider(\"max_length\", 0, 8192, 512, step=1)\n",
    "\n",
    "# 创建一个标题和一个副标题\n",
    "st.title(\"💬 甄嬛\")\n",
    "st.caption(\"🚀 A streamlit chatbot powered by huanhuan\")\n",
    "\n",
    "\n",
    "\n",
    "# 定义一个函数，用于获取模型和 tokenizer\n",
    "@st.cache_resource\n",
    "def get_model():\n",
    "\n",
    "    mode_path = '/root/autodl-tmp/self-llm/model/Qwen/Qwen2.5-7B-Instruct'\n",
    "    lora_path = './output/Qwen2.5_instruct_lora/checkpoint-500' # 这里改称你的 lora 输出对应 checkpoint 地址\n",
    "    \n",
    "    # 加载tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(mode_path, trust_remote_code=True)\n",
    "    \n",
    "    # 加载模型\n",
    "    model = AutoModelForCausalLM.from_pretrained(mode_path, device_map=\"auto\",torch_dtype=torch.bfloat16, trust_remote_code=True).eval()\n",
    "    \n",
    "    # 加载lora权重\n",
    "    model = PeftModel.from_pretrained(model, model_id=lora_path)\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "# 加载 Qwen2.5 的 model 和 tokenizer\n",
    "tokenizer, model = get_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203b3c39-d35c-491c-b486-8a01b924ca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 20:26:32.104 Session state does not function when running a script without `streamlit run`\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"messages\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/streamlit/runtime/state/session_state.py:378\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/streamlit/runtime/state/session_state.py:423\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 423\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/streamlit/runtime/state/session_state_proxy.py:119\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/streamlit/runtime/state/session_state_proxy.py:90\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     89\u001b[0m require_valid_user_key(key)\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/streamlit/runtime/state/safe_session_state.py:113\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/streamlit/runtime/state/session_state.py:380\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"messages\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m贵人安好，贵人可有吩咐？臣妾必定尽力而为 \u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 遍历 session_state 中的所有消息，并显示在聊天界面上\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m:\n\u001b[1;32m      7\u001b[0m     st\u001b[38;5;241m.\u001b[39mchat_message(msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mwrite(msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 如果用户在聊天输入框中输入了内容，则执行以下操作\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/streamlit/runtime/state/session_state_proxy.py:121\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[0;31mAttributeError\u001b[0m: st.session_state has no attribute \"messages\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization"
     ]
    }
   ],
   "source": [
    "\n",
    "# 如果 session_state 中没有 \"messages\"，则创建一个包含默认消息的列表\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state[\"messages\"] = [{\"role\": \"assistant\", \"content\": \"贵人安好，贵人可有吩咐？臣妾必定尽力而为 \"}]\n",
    "\n",
    "# 遍历 session_state 中的所有消息，并显示在聊天界面上\n",
    "for msg in st.session_state.messages:\n",
    "    st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
    "\n",
    "# 如果用户在聊天输入框中输入了内容，则执行以下操作\n",
    "if prompt := st.chat_input():\n",
    "\n",
    "    # 在聊天界面上显示用户的输入\n",
    "    st.chat_message(\"user\").write(prompt)\n",
    "\n",
    "    # 将用户输入添加到 session_state 中的 messages 列表中\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": \"假设你是皇帝身边的女人--甄嬛。\"})\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    # 将对话输入模型，获得返回\n",
    "    input_ids = tokenizer.apply_chat_template(st.session_state.messages,tokenize=False,add_generation_prompt=True)\n",
    "    model_inputs = tokenizer([input_ids], return_tensors=\"pt\").to('cuda')\n",
    "    generated_ids = model.generate(model_inputs.input_ids,max_new_tokens=max_length)\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    # 将模型的输出添加到 session_state 中的 messages 列表中\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "    # 在聊天界面上显示模型的输出\n",
    "    st.chat_message(\"assistant\").write(response)\n",
    "    # print(st.session_state) # 打印 session_state 调试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec0d2a-563a-488f-8e75-77551604ee30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
