{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a4f40ae-70ee-4079-b388-c69eff8e9940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 396, 'content': '没爹的黑孩到处扔', 'output': '没爹的黑孩 | 到处扔 | Racism | hate [END]'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 方法一：使用 with 语句自动管理文件的打开和关闭\n",
    "file_path = 'raw/train.json'\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # 读取并解析 JSON 数据\n",
    "        data = json.load(file)\n",
    "        # 打印读取的数据\n",
    "        print(data[0])\n",
    "except FileNotFoundError:\n",
    "    print(f\"文件 {file_path} 未找到。\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"文件 {file_path} 不是有效的 JSON 格式。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97eb870e-a811-4fd1-a9a6-fd2ef712444a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 4169, 'content': '飞周兄弟还不认亲？兄弟啊，还袭击？'}\n"
     ]
    }
   ],
   "source": [
    "# 方法一：使用 with 语句自动管理文件的打开和关闭\n",
    "file_path = 'raw/test1.json'\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # 读取并解析 JSON 数据\n",
    "        test_data = json.load(file)\n",
    "        # 打印读取的数据\n",
    "        print(test_data[0])\n",
    "except FileNotFoundError:\n",
    "    print(f\"文件 {file_path} 未找到。\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"文件 {file_path} 不是有效的 JSON 格式。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea237e59-bbd1-41fa-8cdd-76f722b3ceea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' LGBTQ',\n",
       " ' LGBTQ ',\n",
       " ' Racism',\n",
       " ' Racism ',\n",
       " ' Region',\n",
       " ' Region ',\n",
       " ' Sexism',\n",
       " ' Sexism ',\n",
       " ' non-hate ',\n",
       " ' others',\n",
       " ' others '}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "for d in data:\n",
    "    a.append(d['output'].split('|')[2].split(',')[0])\n",
    "set(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc1b8f5d-ba08-4215-9150-6fe98221e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_group_list = ['LGBTQ','Racism','Region','Sexism','others','non-hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0532d0c-3ce2-4c5a-b273-ee016e3fd4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = {'id': 5219, 'content': '想反女权还得看女权，舔狗龟男理中客们不是男人能打醒的', 'output': '女权 | 想反女权还得看女权 | Sexism | hate [SEP] 舔狗龟男理中客们 | 不是男人能打醒的 | Sexism | hate [END]'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61b4db7e-40a4-4ae4-8df9-de8826c5ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''本次微调任务为细粒度片段级中文仇恨言论识别，基于给定的文本，任务的输入为社交媒体文本，输出为仇恨四元组，顺序依次为评论对象（Target）、论点（Argument）、目标群体（Targeted Group）、是否仇恨（Hateful）。具体说明如下：\n",
    "\n",
    "评论对象（Target）：帖子的评述对象，如一个人或一个群体。当实例无具体目标时设为NULL。\n",
    "\n",
    "论点（Argument）：包含对评论目标关键论点的信息片段。\n",
    "\n",
    "目标群体（Targeted Group）：指包含仇恨信息的评论对象-论点对涉及的目标群体。标注的目标群体包括LGBTQ,Racism,Region,Sexism,others共5类。\n",
    "\n",
    "是否仇恨（Hateful）：评论对象-论点对是否构成了对某些群体的仇恨言论。有是hate没有是non-hate。对于非仇恨文本和不包含特定群体的一般攻击性言论，设为Non-hate。\n",
    "\n",
    "由于样本中可能有多个评论对象，因此可以包含多个四元组。 每个四元组中各个元素之间用\" | \"分割，并利用 [END] 结尾；如果一条样本中包含多个四元组，不同四元组之间利用 [SEP] 分割。\n",
    "\n",
    "我现在的训练数据是例如这种格式的，这是其中一条样例，content是需要识别的内容，output是输出的仇恨四元组：\n",
    "{'id': 5219,\n",
    " 'content': '想反女权还得看女权，舔狗龟男理中客们不是男人能打醒的',\n",
    " 'output': '女权 | 想反女权还得看女权 | Sexism | hate [SEP] 舔狗龟男理中客们 | 不是男人能打醒的 | Sexism | hate [END]'}\n",
    "\n",
    "我应该如何设计instruction，把这些数据变成能lora微调出好效果的这种格式{\"instruction\": \"\",\"input\": \"\",\"output\": \"\"}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e7c2e9a-379a-490f-a272-45fdeadd7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = []\n",
    "for d in data:\n",
    "    tmp_dic = {}\n",
    "    tmp_dic[\"instruction\"] = '''请从中文社交媒体文本中识别仇恨言论四元组。按以下要求处理：\\n1.识别评论对象(Target)，无目标时写NULL\\n2.提取对应论点(Argument)\\n3.确定目标群体(Targeted Group)：LGBTQ/Racism/Region/Sexism/others\\n4.判断是否仇恨(Hateful)：hate/Non-hate\\n\\n输出格式：Target | Argument | Targeted Group | Hateful [SEP]... [END]\\n多个四元组用[SEP]分隔，最后用[END]结尾'''\n",
    "    tmp_dic[\"input\"] = d['content']\n",
    "    tmp_dic[\"output\"] = d['output']\n",
    "    train_json.append(tmp_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a087094-1be4-4f58-8608-fe319cc9b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_json = []\n",
    "for d in test_data:\n",
    "    tmp_dic = {}\n",
    "    tmp_dic[\"instruction\"] = '''请从中文社交媒体文本中识别仇恨言论四元组。按以下要求处理：\\n1.识别评论对象(Target)，无目标时写NULL\\n2.提取对应论点(Argument)\\n3.确定目标群体(Targeted Group)：LGBTQ/Racism/Region/Sexism/others\\n4.判断是否仇恨(Hateful)：hate/Non-hate\\n\\n输出格式：Target | Argument | Targeted Group | Hateful [SEP]... [END]\\n多个四元组用[SEP]分隔，最后用[END]结尾'''\n",
    "    tmp_dic['id'] = d['id']\n",
    "    tmp_dic[\"input\"] = d['content']\n",
    "    tmp_dic[\"output\"] = \"\"\n",
    "    test_json.append(tmp_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d9b6b16-b3f2-4108-a1b1-f98f783e44eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已成功保存到 train_json/train_json.json\n"
     ]
    }
   ],
   "source": [
    "# 方法一：使用 with 语句自动管理文件的打开和关闭\n",
    "file_path = 'train_json/train_json.json'\n",
    "try:\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        # 将 list 转换为 JSON 格式并写入文件\n",
    "        json.dump(train_json, file, ensure_ascii=False, indent=4)\n",
    "    print(f\"数据已成功保存到 {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"保存文件时出现错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7103f71-de21-40d8-893d-cccd36bc798d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已成功保存到 train_json/test_json.json\n"
     ]
    }
   ],
   "source": [
    "# 方法一：使用 with 语句自动管理文件的打开和关闭\n",
    "file_path = 'train_json/test_json.json'\n",
    "try:\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        # 将 list 转换为 JSON 格式并写入文件\n",
    "        json.dump(test_json, file, ensure_ascii=False, indent=4)\n",
    "    print(f\"数据已成功保存到 {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"保存文件时出现错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c61ad383-2adf-4ec3-a375-e4eaa2286003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 396, 'content': '没爹的黑孩到处扔', 'output': '没爹的黑孩 | 到处扔 | Racism | hate [END]'}\n"
     ]
    }
   ],
   "source": [
    "# 方法一：使用 with 语句自动管理文件的打开和关闭\n",
    "file_path = 'train_json/train_json.json'\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # 读取并解析 JSON 数据\n",
    "        train_data = json.load(file)\n",
    "        # 打印读取的数据\n",
    "        print(data[0])\n",
    "except FileNotFoundError:\n",
    "    print(f\"文件 {file_path} 未找到。\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"文件 {file_path} 不是有效的 JSON 格式。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8205501d-dcf4-4d17-921f-f1087778182b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
